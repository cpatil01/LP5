{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sZOYh4-LIrU2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "import pandas as pd\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Boston Housing dataset\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWRMxHvUJE7f",
        "outputId": "895cca2e-4a00-48a2-bb0d-69dfa8946e50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Boston Housing dataset\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "\n",
        "\n",
        "ct = make_column_transformer((MinMaxScaler(),[0,1,2,3,4,5,6,7,8,9,10,11,12]))\n"
      ],
      "metadata": {
        "id": "-hcxx9UZJQyM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "PnTcfeOKJWBF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the deep neural network model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "C2kR-Lg0JYq9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "_XXKBOCZJcZn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlZHx3w-JiHc",
        "outputId": "01548bf2-d2fc-4808-fef7-7608b5606130"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "13/13 [==============================] - 1s 3ms/step - loss: 557.2103\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 471.0528\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 324.5777\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 137.4796\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 58.1464\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 38.1570\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 28.6082\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 23.9697\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 21.1474\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 19.4733\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 17.6517\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 16.1880\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 15.5042\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 14.5159\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.6828\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 13.1502\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.7174\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 12.1672\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.7880\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.4910\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 11.1974\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.9844\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.8200\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.5075\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.3034\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 10.1360\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 10.1793\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 10.1388\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 9.9716\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.5432\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.4603\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.3948\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.3650\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.2620\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.9257\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.7724\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.7239\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.7056\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.5594\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.5460\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.4257\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.5303\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.2076\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.2004\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 8.0338\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.0179\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.8886\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.8450\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.7707\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.7823\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.6547\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.6619\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.5833\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.6820\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.4746\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.2788\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.2490\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.2348\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.1071\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.3269\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.0828\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.9786\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.8756\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.8864\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.8731\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.8176\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.7873\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.6686\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.6726\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.5717\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.6625\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.4748\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.6293\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.4274\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3307\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.4827\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.4423\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.3192\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3761\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.3555\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.3844\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2454\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.0000\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.9432\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9797\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.8582\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7740\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8745\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9301\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8644\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9127\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5606\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5055\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3894\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5560\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4573\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4237\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.3095\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7337\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6079\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6435\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5719\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1980\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1758\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0545\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9074\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9412\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9620\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9006\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7991\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7338\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8518\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7412\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7176\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9394\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8238\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6416\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8452\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5429\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3245\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3423\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3414\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1394\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1516\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.1372\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0411\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9620\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2226\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0624\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9231\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7884\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7464\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7956\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.9134\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7750\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7370\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7260\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.6936\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.7414\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.8015\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4834\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4439\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4431\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3963\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.4191\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2825\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3303\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2760\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.3656\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.1533\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.1768\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.2358\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.0799\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.0534\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.0397\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.0385\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.9370\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.9886\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1810\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.8480\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 2.9925\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.0468\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.1151\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.0437\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.0088\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.9181\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.8167\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.9484\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.0016\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.8636\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.6236\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.5620\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.7836\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.7504\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.6508\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.5760\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.8084\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.7241\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.4198\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.3937\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.5329\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.5488\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.3588\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.3671\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.3643\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.3446\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.6379\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.4973\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.2363\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.2426\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.1485\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.1250\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.1402\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.1440\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.1799\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.1404\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.2008\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.1207\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.1662\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2.1751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing set\n",
        "loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Mean Squared Error (MSE) on test data:', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO5m5bAYJld_",
        "outputId": "5c8e74c2-dadf-498c-8f5e-e35f0caf3772"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE) on test data: 11.633854866027832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the X_test dataset\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "predictions[1] , y_test[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jldKVtdnJs2s",
        "outputId": "7259f013-806b-4108-fc6f-076f06d1b69f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([19.035053], dtype=float32), 18.8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the predicted prices\n",
        "for i in range(len(predictions)):\n",
        "    print(f\"Predicted price: {predictions[i][0]:.2f}, Actual price: {y_test[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToJM-6_eJwFx",
        "outputId": "1f591de5-02ae-49ed-e737-aa8f0217568c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price: 9.29, Actual price: 7.2\n",
            "Predicted price: 19.04, Actual price: 18.8\n",
            "Predicted price: 20.66, Actual price: 19.0\n",
            "Predicted price: 36.09, Actual price: 27.0\n",
            "Predicted price: 24.62, Actual price: 22.2\n",
            "Predicted price: 24.64, Actual price: 24.5\n",
            "Predicted price: 26.88, Actual price: 31.2\n",
            "Predicted price: 21.71, Actual price: 22.9\n",
            "Predicted price: 18.79, Actual price: 20.5\n",
            "Predicted price: 20.24, Actual price: 23.2\n",
            "Predicted price: 19.59, Actual price: 18.6\n",
            "Predicted price: 17.13, Actual price: 14.5\n",
            "Predicted price: 16.01, Actual price: 17.8\n",
            "Predicted price: 43.62, Actual price: 50.0\n",
            "Predicted price: 24.47, Actual price: 20.8\n",
            "Predicted price: 21.09, Actual price: 24.3\n",
            "Predicted price: 25.43, Actual price: 24.2\n",
            "Predicted price: 18.24, Actual price: 19.8\n",
            "Predicted price: 19.44, Actual price: 19.1\n",
            "Predicted price: 21.13, Actual price: 22.7\n",
            "Predicted price: 11.00, Actual price: 12.0\n",
            "Predicted price: 10.92, Actual price: 10.2\n",
            "Predicted price: 22.36, Actual price: 20.0\n",
            "Predicted price: 13.70, Actual price: 18.5\n",
            "Predicted price: 18.93, Actual price: 20.9\n",
            "Predicted price: 21.94, Actual price: 23.0\n",
            "Predicted price: 29.02, Actual price: 27.5\n",
            "Predicted price: 30.02, Actual price: 30.1\n",
            "Predicted price: 11.10, Actual price: 9.5\n",
            "Predicted price: 20.14, Actual price: 22.0\n",
            "Predicted price: 19.11, Actual price: 21.2\n",
            "Predicted price: 14.88, Actual price: 14.1\n",
            "Predicted price: 33.40, Actual price: 33.1\n",
            "Predicted price: 24.11, Actual price: 23.4\n",
            "Predicted price: 20.33, Actual price: 20.1\n",
            "Predicted price: 7.96, Actual price: 7.4\n",
            "Predicted price: 18.21, Actual price: 15.4\n",
            "Predicted price: 14.94, Actual price: 23.8\n",
            "Predicted price: 18.78, Actual price: 20.1\n",
            "Predicted price: 25.66, Actual price: 24.5\n",
            "Predicted price: 32.77, Actual price: 33.0\n",
            "Predicted price: 26.90, Actual price: 28.4\n",
            "Predicted price: 13.26, Actual price: 14.1\n",
            "Predicted price: 43.58, Actual price: 46.7\n",
            "Predicted price: 30.68, Actual price: 32.5\n",
            "Predicted price: 28.10, Actual price: 29.6\n",
            "Predicted price: 29.25, Actual price: 28.4\n",
            "Predicted price: 20.03, Actual price: 19.8\n",
            "Predicted price: 21.97, Actual price: 20.2\n",
            "Predicted price: 23.58, Actual price: 25.0\n",
            "Predicted price: 33.80, Actual price: 35.4\n",
            "Predicted price: 22.27, Actual price: 20.3\n",
            "Predicted price: 10.14, Actual price: 9.7\n",
            "Predicted price: 13.44, Actual price: 14.5\n",
            "Predicted price: 35.85, Actual price: 34.9\n",
            "Predicted price: 28.28, Actual price: 26.6\n",
            "Predicted price: 11.79, Actual price: 7.2\n",
            "Predicted price: 48.30, Actual price: 50.0\n",
            "Predicted price: 36.38, Actual price: 32.4\n",
            "Predicted price: 24.79, Actual price: 21.6\n",
            "Predicted price: 18.33, Actual price: 29.8\n",
            "Predicted price: 15.36, Actual price: 13.1\n",
            "Predicted price: 15.98, Actual price: 27.5\n",
            "Predicted price: 21.20, Actual price: 21.2\n",
            "Predicted price: 23.88, Actual price: 23.1\n",
            "Predicted price: 19.89, Actual price: 21.9\n",
            "Predicted price: 14.14, Actual price: 13.0\n",
            "Predicted price: 20.80, Actual price: 23.2\n",
            "Predicted price: 13.23, Actual price: 8.1\n",
            "Predicted price: 8.28, Actual price: 5.6\n",
            "Predicted price: 20.41, Actual price: 21.7\n",
            "Predicted price: 28.60, Actual price: 29.6\n",
            "Predicted price: 29.06, Actual price: 19.6\n",
            "Predicted price: 13.27, Actual price: 7.0\n",
            "Predicted price: 26.05, Actual price: 26.4\n",
            "Predicted price: 19.83, Actual price: 18.9\n",
            "Predicted price: 18.73, Actual price: 20.9\n",
            "Predicted price: 24.93, Actual price: 28.1\n",
            "Predicted price: 36.54, Actual price: 35.4\n",
            "Predicted price: 9.79, Actual price: 10.2\n",
            "Predicted price: 23.33, Actual price: 24.3\n",
            "Predicted price: 38.25, Actual price: 43.1\n",
            "Predicted price: 15.84, Actual price: 17.6\n",
            "Predicted price: 13.69, Actual price: 15.4\n",
            "Predicted price: 19.18, Actual price: 16.2\n",
            "Predicted price: 17.68, Actual price: 27.1\n",
            "Predicted price: 25.30, Actual price: 21.4\n",
            "Predicted price: 19.97, Actual price: 21.5\n",
            "Predicted price: 22.97, Actual price: 22.4\n",
            "Predicted price: 24.37, Actual price: 25.0\n",
            "Predicted price: 19.00, Actual price: 16.6\n",
            "Predicted price: 19.84, Actual price: 18.6\n",
            "Predicted price: 25.39, Actual price: 22.0\n",
            "Predicted price: 40.40, Actual price: 42.8\n",
            "Predicted price: 38.00, Actual price: 35.1\n",
            "Predicted price: 22.81, Actual price: 21.5\n",
            "Predicted price: 35.48, Actual price: 36.0\n",
            "Predicted price: 28.97, Actual price: 21.9\n",
            "Predicted price: 24.98, Actual price: 24.1\n",
            "Predicted price: 51.57, Actual price: 50.0\n",
            "Predicted price: 31.14, Actual price: 26.7\n",
            "Predicted price: 19.08, Actual price: 25.0\n"
          ]
        }
      ]
    }
  ]
}